{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd6d1db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install -U langchain\n",
    "# ! pip install langchain_text_splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf3868a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"\"\"\n",
    "Once you've loaded documents, you'll often want to transform them to better suit your application. The simplest example is you may want to split a long document into smaller chunks that can fit into your model's context window. LangChain has a number of built-in document transformers that make it easy to split, combine, filter, and otherwise manipulate documents.\n",
    "\n",
    "When you want to deal with long pieces of text, it is necessary to split up that text into chunks. As simple as this sounds, there is a lot of potential complexity here. Ideally, you want to keep the semantically related pieces of text together. What \"semantically related\" means could depend on the type of text. This notebook showcases several ways to do that.\n",
    "\n",
    "At a high level, text splitters work as following:\n",
    "\n",
    "Split the text up into small, semantically meaningful chunks (often sentences).\n",
    "Start combining these small chunks into a larger chunk until you reach a certain size (as measured by some function).\n",
    "Once you reach that size, make that chunk its own piece of text and then start creating a new chunk of text with some overlap (to keep context between chunks).\n",
    "That means there are two different axes along which you can customize your text splitter:\n",
    "\n",
    "How the text is split\n",
    "How the chunk size is measured\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af74f228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "366"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\"\"\"Once you've loaded documents, you'll often want to transform them to better suit your application. The simplest example is you may want to split a long document into smaller chunks that can fit into your model's context window. LangChain has a number of built-in document transformers that make it easy to split, combine, filter, and otherwise manipulate documents.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "554d4c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "363"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\"\"\"When you want to deal with long pieces of text, it is necessary to split up that text into chunks. As simple as this sounds, there is a lot of potential complexity here. Ideally, you want to keep the semantically related pieces of text together. What \"semantically related\" means could depend on the type of text. This notebook showcases several ways to do that.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d099550",
   "metadata": {},
   "source": [
    "### Understanding RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd2e965a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 781\n",
      "Once you've loaded documents, you'll often want to transform them to better suit your application. The simplest example is you may want to split a long document into smaller chunks that can fit into your model's context window. LangChain has a number of built-in document transformers that make it easy to split, combine, filter, and otherwise manipulate documents.\n",
      "\n",
      "When you want to deal with long pieces of text, it is necessary to split up that text into chunks. As simple as this sounds, there is a lot of potential complexity here. Ideally, you want to keep the semantically related pieces of text together. What \"semantically related\" means could depend on the type of text. This notebook showcases several ways to do that.\n",
      "\n",
      "At a high level, text splitters work as following:\n",
      "1 501\n",
      "Split the text up into small, semantically meaningful chunks (often sentences).\n",
      "Start combining these small chunks into a larger chunk until you reach a certain size (as measured by some function).\n",
      "Once you reach that size, make that chunk its own piece of text and then start creating a new chunk of text with some overlap (to keep context between chunks).\n",
      "That means there are two different axes along which you can customize your text splitter:\n",
      "\n",
      "How the text is split\n",
      "How the chunk size is measured\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# text = \"This is a piece of text.\"\n",
    "chunk_size = 800\n",
    "chunk_overlap = 0\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "chunks = splitter.split_text(data)\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "# for chunk in chunks:\n",
    "    print(i, len(chunk))\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83686157",
   "metadata": {},
   "source": [
    "### Understand chunk_overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75a2487b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"\"\"Madam Speaker, Madam Vice President, our First Lady and Second Gentleman. Members of Congress and of Congress and the Cabinet. Justices of the Supreme Court. My fellow Americans.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7fd7180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Madam Speaker, Madam Vice President, our First Lady and Second Gentleman. Members of Congress and of Congress and the Cabinet. Justices of the Supreme Court. My fellow Americans.\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b407eb62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 40\n",
      "Madam Speaker, Madam Vice President, our\n",
      "1 36\n",
      "our First Lady and Second Gentleman.\n",
      "2 39\n",
      "Members of Congress and of Congress and\n",
      "3 32\n",
      "and the Cabinet. Justices of the\n",
      "4 31\n",
      "of the Supreme Court. My fellow\n",
      "5 20\n",
      "My fellow Americans.\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# text = \"This is a piece of text.\"\n",
    "chunk_size = 40\n",
    "chunk_overlap = 10\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "\n",
    "chunks = splitter.split_text(data)\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "# for chunk in chunks:\n",
    "    print(i, len(chunk))\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9812e2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "393024ad",
   "metadata": {},
   "source": [
    "### CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cfeae2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    chunk_size=128,\n",
    "    chunk_overlap=0,\n",
    "    separator=\" \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "903df456",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = text_splitter.split_text(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bf228955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Once you've loaded documents, you'll often want to transform them to better suit your application. The simplest example is you\",\n",
       " \"may want to split a long document into smaller chunks that can fit into your model's context window. LangChain has a number of\",\n",
       " 'built-in document transformers that make it easy to split, combine, filter, and otherwise manipulate documents.\\n\\nWhen you want',\n",
       " 'to deal with long pieces of text, it is necessary to split up that text into chunks. As simple as this sounds, there is a lot of',\n",
       " 'potential complexity here. Ideally, you want to keep the semantically related pieces of text together. What \"semantically',\n",
       " 'related\" means could depend on the type of text. This notebook showcases several ways to do that.\\n\\nAt a high level, text',\n",
       " 'splitters work as following:\\n\\nSplit the text up into small, semantically meaningful chunks (often sentences).\\nStart combining',\n",
       " 'these small chunks into a larger chunk until you reach a certain size (as measured by some function).\\nOnce you reach that size,',\n",
       " 'make that chunk its own piece of text and then start creating a new chunk of text with some overlap (to keep context between',\n",
       " 'chunks).\\nThat means there are two different axes along which you can customize your text splitter:\\n\\nHow the text is split\\nHow',\n",
       " 'the chunk size is measured']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccb5589",
   "metadata": {},
   "source": [
    "### RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9760efe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aff10e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=800,\n",
    "    chunk_overlap=20,\n",
    "    length_function=len,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "20ba8dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = text_splitter.split_text(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "09b58aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Once you\\'ve loaded documents, you\\'ll often want to transform them to better suit your application. The simplest example is you may want to split a long document into smaller chunks that can fit into your model\\'s context window. LangChain has a number of built-in document transformers that make it easy to split, combine, filter, and otherwise manipulate documents.\\n\\nWhen you want to deal with long pieces of text, it is necessary to split up that text into chunks. As simple as this sounds, there is a lot of potential complexity here. Ideally, you want to keep the semantically related pieces of text together. What \"semantically related\" means could depend on the type of text. This notebook showcases several ways to do that.\\n\\nAt a high level, text splitters work as following:',\n",
       " 'Split the text up into small, semantically meaningful chunks (often sentences).\\nStart combining these small chunks into a larger chunk until you reach a certain size (as measured by some function).\\nOnce you reach that size, make that chunk its own piece of text and then start creating a new chunk of text with some overlap (to keep context between chunks).\\nThat means there are two different axes along which you can customize your text splitter:\\n\\nHow the text is split\\nHow the chunk size is measured']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f103f0b",
   "metadata": {},
   "source": [
    "### Token Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d48e0207",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=128, chunk_overlap=20\n",
    ")\n",
    "texts = text_splitter.split_text(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e1b67477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Once you've loaded documents, you'll often want to transform them to better suit your application. The simplest example is you may want to split a long document into smaller chunks that can fit into your model's context window. LangChain has a number of built-in document transformers that make it easy to split, combine, filter, and otherwise manipulate documents.\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e19961e",
   "metadata": {},
   "source": [
    "### Splitting Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "103b21f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import (\n",
    "    Language,\n",
    "    RecursiveCharacterTextSplitter,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "034d3c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"app_updated.py\") as fp:\n",
    "    data = fp.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e49de3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5e1124ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "python_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.PYTHON, chunk_size=200, chunk_overlap=0\n",
    ")\n",
    "\n",
    "# python_docs = python_splitter.split_text(data)\n",
    "python_docs = python_splitter.split_text(data)\n",
    "python_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4554e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef36cb5e",
   "metadata": {},
   "source": [
    "### Markdown splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "93cc530c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"\"\"\n",
    "# Fun in California\n",
    "\n",
    "## Driving\n",
    "\n",
    "Try driving on the 1 down to San Diego\n",
    "\n",
    "### Food\n",
    "\n",
    "Make sure to eat a burrito while you're there\n",
    "\n",
    "## Hiking\n",
    "\n",
    "Go to Yosemite\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c97305da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import MarkdownHeaderTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cc917b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"###\", \"Header 3\"),\n",
    "]\n",
    "splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d4ab3636",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = text_splitter.split_text(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9324cae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 # Fun in California\n",
      "\n",
      "## Driving\n",
      "\n",
      "Try driving on the 1 down to San Diego\n",
      "\n",
      "### Food\n",
      "\n",
      "Make sure to eat a burrito while you're\n",
      "1 there\n",
      "\n",
      "## Hiking\n",
      "\n",
      "Go to Yosemite\n"
     ]
    }
   ],
   "source": [
    "for i, chunk in enumerate(texts):\n",
    "    print(i, chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9025d39",
   "metadata": {},
   "source": [
    "### Semantic Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4bfecef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet langchain_experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89888501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ff099ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5116b4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b1ac4c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = SemanticChunker(OpenAIEmbeddings(openai_api_key=\"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\"), breakpoint_threshold_type=\"percentile\", breakpoint_threshold_amount=50)\n",
    "# text_splitter = SemanticChunker(OpenAIEmbeddings(openai_api_key=\"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\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b3a59a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"\"\"\n",
    "Paris, the capital city of France, is renowned for its rich history, iconic landmarks, and vibrant culture. From the magnificent Eiffel Tower standing tall against the skyline to the charming cobblestone streets of Montmartre, Paris exudes an undeniable allure. Visitors flock to marvel at masterpieces in the Louvre Museum, stroll along the Seine River, and indulge in exquisite French cuisine at quaint bistros. With its romantic ambiance and timeless elegance, Paris continues to captivate hearts and minds as one of the most enchanting cities in the world.\n",
    "\n",
    "Computers have revolutionized the way we live, work, and interact with the world around us. From the early mechanical calculators to the sophisticated machines of today, computers have evolved exponentially, becoming integral to nearly every aspect of modern life. These powerful devices process vast amounts of data, enable seamless communication across the globe, and drive innovation in fields ranging from science and medicine to business and entertainment. With their unparalleled capabilities and ever-expanding potential, computers continue to shape the course of human progress in profound ways.\n",
    "\n",
    "Adolf Hitler, the infamous dictator of Nazi Germany, rose to power in the 1930s, plunging Europe into the depths of World War II and perpetrating unspeakable atrocities during the Holocaust. Through his fiery rhetoric and ruthless policies, Hitler sought to impose his radical ideology of racial purity and expansionist ambitions upon the world. His regime systematically persecuted and murdered millions of innocent civilians, forever staining history with the horrors of genocide. Despite his ultimate defeat and the downfall of the Third Reich, Hitler's legacy serves as a haunting reminder of the dangers of unchecked tyranny and the enduring importance of safeguarding democracy and human rights.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "03e1cfb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 561\n",
      "\n",
      "Paris, the capital city of France, is renowned for its rich history, iconic landmarks, and vibrant culture. From the magnificent Eiffel Tower standing tall against the skyline to the charming cobblestone streets of Montmartre, Paris exudes an undeniable allure. Visitors flock to marvel at masterpieces in the Louvre Museum, stroll along the Seine River, and indulge in exquisite French cuisine at quaint bistros. With its romantic ambiance and timeless elegance, Paris continues to captivate hearts and minds as one of the most enchanting cities in the world.\n",
      "1 91\n",
      "Computers have revolutionized the way we live, work, and interact with the world around us.\n",
      "2 369\n",
      "From the early mechanical calculators to the sophisticated machines of today, computers have evolved exponentially, becoming integral to nearly every aspect of modern life. These powerful devices process vast amounts of data, enable seamless communication across the globe, and drive innovation in fields ranging from science and medicine to business and entertainment.\n",
      "3 332\n",
      "With their unparalleled capabilities and ever-expanding potential, computers continue to shape the course of human progress in profound ways. Adolf Hitler, the infamous dictator of Nazi Germany, rose to power in the 1930s, plunging Europe into the depths of World War II and perpetrating unspeakable atrocities during the Holocaust.\n",
      "4 154\n",
      "Through his fiery rhetoric and ruthless policies, Hitler sought to impose his radical ideology of racial purity and expansionist ambitions upon the world.\n",
      "5 355\n",
      "His regime systematically persecuted and murdered millions of innocent civilians, forever staining history with the horrors of genocide. Despite his ultimate defeat and the downfall of the Third Reich, Hitler's legacy serves as a haunting reminder of the dangers of unchecked tyranny and the enduring importance of safeguarding democracy and human rights.\n"
     ]
    }
   ],
   "source": [
    "chunks = text_splitter.split_text(data)\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "# for chunk in chunks:\n",
    "    print(i, len(chunk))\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232b01d8",
   "metadata": {},
   "source": [
    "### PDF parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2b166c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install unstructured\n",
    "# ! pip install pdf2image\n",
    "# ! pip install -U unstructured pdf2image pdfminer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fe2583d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install -U pdfminer.six\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "517f473f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install pillow_heif\n",
    "# ! pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0477bc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27af76f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install unstructured_pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9877dd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install unstructured_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dea03e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install pikepdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e9ce6d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "from unstructured.staging.base import elements_to_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ef6dcf9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Following dependencies are missing: pikepdf. Please install them using `pip install pikepdf`.\n",
      "PDF text extraction failed, skip text extraction...\n",
      "Some weights of the model checkpoint at microsoft/table-transformer-structure-recognition were not used when initializing TableTransformerForObjectDetection: ['model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked']\n",
      "- This IS expected if you are initializing TableTransformerForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TableTransformerForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "filename = \"SalesforceFinancial.pdf\"\n",
    "\n",
    "# Extracts the elements from the PDF\n",
    "elements = partition_pdf(\n",
    "    filename=filename,\n",
    "\n",
    "    # Unstructured Helpers\n",
    "    strategy=\"hi_res\", \n",
    "    infer_table_structure=True, \n",
    "    model_name=\"yolox\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e2f9f005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<unstructured.documents.elements.NarrativeText at 0x7f7333abaf50>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7f7328730410>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7f7328730510>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7f7328730610>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7f7328730710>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7f7328730890>,\n",
       " <unstructured.documents.elements.Title at 0x7f73287b24d0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7f7328730990>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7f7328730a90>,\n",
       " <unstructured.documents.elements.Table at 0x7f7328730b90>,\n",
       " <unstructured.documents.elements.Title at 0x7f73285e83d0>,\n",
       " <unstructured.documents.elements.Text at 0x7f73285e8e10>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7f7328730c50>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x7f7328730dd0>]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c495bab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<table><thead><th>Revenue\")</th><th>Guidance $7.69 - $7.70 Billion</th><th>Guidance $31.7 - $31.8 Billion</th></thead><tr><td>Y/Y Growth</td><td>~21%</td><td>~20%</td></tr><tr><td>FX Impact?)</td><td>~($200M) y/y FX</td><td>~($600M) y/y FX)</td></tr><tr><td>GAAP operating margin</td><td></td><td>~3.8%</td></tr><tr><td>Non-GAAP operating margin”)</td><td></td><td>~20.4%</td></tr><tr><td>GAAP earnings (loss) per share</td><td>($0.03) - ($0.02)</td><td>$0.38 - $0.40</td></tr><tr><td>Non-GAAP earnings per share</td><td>$1.01 - $1.02</td><td>$4.74 - $4.76</td></tr><tr><td>Operating Cash Flow Growth (Y/Y)</td><td></td><td>~21% - 22%</td></tr><tr><td>Current Remaining Performance Obligation Growth (Y/Y)</td><td>~15%</td><td></td></tr></table>'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elements[-5].metadata.text_as_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d5176700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Operating Margin: First quarter GAAP operating margin was 0.3%. First quarter non-GAAP operating margin was 17.6%.'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elements[1].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8638ba83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'detection_class_prob': 0.9110447764396667,\n",
       " 'coordinates': {'points': ((185.0060272216797, 247.2501678466797),\n",
       "   (185.0060272216797, 310.4765930175781),\n",
       "   (1545.081298828125, 310.4765930175781),\n",
       "   (1545.081298828125, 247.2501678466797)),\n",
       "  'system': 'PixelSpace',\n",
       "  'layout_width': 1700,\n",
       "  'layout_height': 2200},\n",
       " 'last_modified': '2024-03-01T15:10:33',\n",
       " 'filetype': 'application/pdf',\n",
       " 'languages': ['eng'],\n",
       " 'page_number': 1,\n",
       " 'filename': 'SalesforceFinancial.pdf'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elements[1].metadata.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1b9e11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
